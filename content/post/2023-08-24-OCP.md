---
title: OCP
date: 2023-08-24
---

# How to setup OCP environment

  1. [Openshift Website](https://console.redhat.com/openshift/)
  1. Install OCP based on the official documents
     * [Red Hat OpenShift Local](https://access.redhat.com/documentation/en-us/red_hat_openshift_local/)
     * Install the cluster with Assisted Installer
       * [Install OpenShift clusters on bare metal](https://console.redhat.com/openshift/assisted-installer/clusters/~new)
       * [Install OpenShift on a single node (SNO)](https://docs.openshift.com/container-platform/4.13/installing/installing_sno/install-sno-installing-sno.html)
  1. Install OCP with [Balazs’ script](https://github.com/bn222/cluster-deployment-automation)
     * Install a vm Single Node OpenShift (SNO)
     * Install a vm control/worker cluster
     * Install a bare mental cluster (Need iDRAC9)

## Openshift Website

Here is the [RedHat Hybird Cloud Console](https://console.redhat.com/openshift/) and
latest [install doc](https://docs.openshift.com/container-platform/4.13/installing/index.html).

There are 2 ways to install the OCP for developer testing. One is via the official document.
Another is use [Balazs' script](https://github.com/bn222/cluster-deployment-automation).

## Install OCP via the official doc

### [Red Hat OpenShift Local](https://access.redhat.com/documentation/en-us/red_hat_openshift_local/)

Red Hat OpenShift Local brings a minimal OpenShift Container Platform 4 cluster and Podman container runtime to your local computer.
These runtimes provide minimal environments for development and testing purposes.
Red Hat OpenShift Local is mainly targeted at running on developers' desktops.

The Local installer need to run as normal user. So we should add the user
to `sudo` group. We also need to set the `systemctl --user` permission.

First, Run as root and set the user permission
```
#!/bin/bash

user=test
# Add the user to sudoer
sudo usermod -aG wheel ${user}

# setup for `systemctl --user status`
# https://serverfault.com/questions/936985/cannot-use-systemctl-user-due-to-failed-to-get-d-bus-connection-permission
cat > /etc/systemd/system/user@$(id ${user}).service <<EOF
[Unit]
Description=User Manager for UID %i
After=systemd-user-sessions.service
# These are present in the RHEL8 version of this file except that the unit is Requires, not Wants.
# It's listed as Wants here so that if this file is used in a RHEL7 settings, it will not fail.
# If a user upgrades from RHEL7 to RHEL8, this unit file will continue to work until it's
# deleted the next time they upgrade Tableau Server itself.
After=user-runtime-dir@%i.service
Wants=user-runtime-dir@%i.service

[Service]
LimitNOFILE=infinity
LimitNPROC=infinity
User=%i
PAMName=systemd-user
Type=notify
# PermissionsStartOnly is deprecated and will be removed in future versions of systemd
# This is required for all systemd versions prior to version 231
PermissionsStartOnly=true
ExecStartPre=/bin/loginctl enable-linger %i
ExecStart=-/lib/systemd/systemd --user
Slice=user-%i.slice
KillMode=mixed
Delegate=yes
TasksMax=infinity
Restart=always
RestartSec=15

[Install]
WantedBy=default.target
EOF

systemctl daemon-reload
systemctl enable user@$(id ${user}).service
systemctl start user@$(id ${user}).service

```

Now su to test uer and start setup
```
#!/bin/bash


wget https://developers.redhat.com/content-gateway/rest/mirror/pub/openshift-v4/clients/crc/latest/crc-linux-amd64.tar.xz
tar xf crc-linux-amd64.tar.xz
mkdir ~/bin
cp crc-linux-*-amd64/crc ~/bin/

# export XDG_RUNTIME_DIR for systemctl --user
#echo [ -z "${XDG_RUNTIME_DIR}" ] && export XDG_RUNTIME_DIR=/run/user/$(id -u) >> .bashrc
export XDG_RUNTIME_DIR=/run/user/$(id -u)

# Start crc
crc setup
crc start
```

If you want to remove the local openshift, just run `crc delete`

If you installed the openshift on a remote server. You can install [haproxy and dnsmasq](https://access.redhat.com/documentation/en-us/red_hat_openshift_local/2.25/html/getting_started_guide/networking#setting_up_redhat_openshift_local_on_a_remote_server) to access the web console.

### Install OpenShift on a single node (SNO)

You can install single-node OpenShift (SNO) using the web-based Assisted Installer
and a discovery ISO that you generate using the Assisted Installer.

Here is the process:
  1. On the administration host, open a browser and navigate to [Red Hat OpenShift Cluster Manager](https://console.redhat.com/openshift/assisted-installer/clusters).
  1. Click `Create Cluster` to create a new cluster.
  1. In the `Cluster name` field, enter a name for the cluster.
  1. In the `Base domain` field, enter a base domain. For example: `example.com`
  1. Select `Install single node OpenShift (SNO)` and complete the rest of the wizard steps. Download the discovery ISO.

After download the discovery ISO. We need to attach the RHCOS discovery ISO to the target host and configure the boot drive order.
If you are using your local machines, you can do this manually. If you are using a beaker machine.
You can [boot from an HTTP-hosted ISO image using the Redfish API](https://docs.openshift.com/container-platform/4.13/installing/installing_sno/install-sno-installing-sno.html#install-booting-from-an-iso-over-http-redfish_install-sno-installing-sno-with-the-assisted-installer).

Here we will take DELL's iDRAC control pannel as example. In beaker, each machine has a remote access controller.
And the IP address is it's own IP + 1. For example, the `wsfd-netdev78.ntdv.lab.eng.bos.redhat.com`'s IP address
is `10.19.188.161`. Then it's iDRAC address will be `10.19.188.162`. The default admin password is `calvin`.

After download the installation ISO and Copy the ISO file to an HTTP server accessible in your network.
We can insert the ISO to target host and set the boot order. With the `idrac_setup.sh` tool, you can just
  1. `sed 's#IMAGE_LINK#your_iso_link#' test.sh`
  1. `./idrac_setup.sh start $your_bmc_ip`
  1. `./idrac_setup.sh reboot $your_bmc_ip` or boot/reboot via beaker power page
  1. Monitor the installation’s progress. Watch the cluster events.
  1. reset the iDRAC setting via `./idrac_setup.sh reset $your_bmc_ip`

After installation, in the Overview page, you can open the `Web Console URL`
and login the cluster with kubeadmin. If you can't login, you can use external
DNS server or local configuration to resolve its hostname.

###  Install OpenShift clusters on bare metal

The steps almost the same with the way we install SNO. The only differences are
  1. Do not select `Install single node OpenShift (SNO)` when create the cluster
  1. We need at least 3 Control plane nodes.
     ![OCP_cluster](/OCP_cluster.png)
  1. We can add more workers after that.
  1. `WARN`: when set the ingress/API IP, we need to choose unused IP addresses
     ![OCP_network](/OCP_network.png)

In the web console overview page you can see the install progress.
![OCP_install](/OCP_install.png)

##  Install OCP with Balazs’ script

Apart from the official way, which need some manually works, on the other hand, it is more stable.
We can use Balazs’ script. With this script we can setup the OCP environment automatically.

Just follow up the README steps you setup the OCP env easily. The down side
is some OCP version may not stable. And require iDRAC9 if you want to install
OCP on bare mental machines.

On the other hand, it's recommend to install the OCP on VMs for testing, which
would save more resources.

## Some TIPs

### How to login the cluster with ssh

There is no way to login cluster with root directly. We can use a special user
core (which has sudo permission) to login CoreOS.

### How to get the kubeadmin password.

With `RedHat Hybird Cloud Console` you can find it from the `Overview` page.
If you are using Balazs’ script. It will start a assisted service(with port 8080)
 on the server you are running. After open the page, you can find the password.

### How to open the web console.

With `RedHat Hybird Cloud Console` you need to edit your DNS or hosts file.
With Balazs’ script, you need to add the following entries to hosts file
```
192.168.122.99	api.vm.redhat.com
192.168.122.101	oauth-openshift.apps.vm.redhat.com
192.168.122.101	console-openshift-console.apps.vm.redhat.com
192.168.122.101	grafana-openshift-monitoring.apps.vm.redhat.com
192.168.122.101	thanos-querier-openshift-monitoring.apps.vm.redhat.com
192.168.122.101	prometheus-k8s-openshift-monitoring.apps.vm.redhat.com
192.168.122.101	alertmanager-main-openshift-monitoring.apps.vm.redhat.com
```

and run sshuttle to forward the DNS requests.

```
sshuttle --dns -v -r root@wsfd-advnetlab127.anl.lab.eng.bos.redhat.com 192.168.122.1/24
```
Then you can open `console-openshift-console.apps.vm.redhat.com` on your browser.
